{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ce67108-91c5-4009-ba50-0b9a3129b65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from scipy import stats\n",
    "import warnings\n",
    "pd.options.mode.chained_assignment = None \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33cf4da0-540e-40ab-b8f6-ced61cd68b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vdf = pd.read_csv(\"beeActivity.csv\")\n",
    "vdf['track_endtime'] = vdf['track_endtime'].apply(lambda x: pd.to_datetime(x))\n",
    "vdf['track_starttime'] = vdf['track_starttime'].apply(lambda x: pd.to_datetime(x))\n",
    "vdf['track_tagid'] = vdf['track_tagid'].apply(lambda x: str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b72406c0-146a-4e71-a310-da04d04a945c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SECONDS THRESHOLD\n",
    "#used to classify multiple detections into part of a single event\n",
    "#also used to tell when two detections are part of different events\n",
    "#by checking the time distance between them\n",
    "t = 15\n",
    "\n",
    "#DISTANCE THRESHOLD\n",
    "#used to classify an event as entering or exiting\n",
    "#when two consecutive detections of the same event \n",
    "#have this distance in y position, they are utilized to predict\n",
    "#the trajectory. If not then it checks the detection prior for\n",
    "#the distance threshold, and continues doing so until it finds\n",
    "#the last detection in the event or until it finds a distance\n",
    "#of more than the threshold\n",
    "\n",
    "t2 = 150\n",
    "\n",
    "#ANGLE THRESHOLD\n",
    "#used to generate angle ranges for classifying as exiting\n",
    "#or entering\n",
    "\n",
    "angle = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592f3a91-1d4b-461c-b296-23f4ea7558b4",
   "metadata": {},
   "source": [
    "## Look at events prior and classify based on y displacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e83b26b-7fff-4f4e-b980-59fb732cc6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def beeCleanPrior(bee):\n",
    "\n",
    "    id = bee['track_tagid'].iloc[0]\n",
    "\n",
    "    new_event = []\n",
    "    datetime = []\n",
    "        \n",
    "    for i in range(len(bee)-1):\n",
    "\n",
    "            time = bee['track_endtime'].iloc[i]\n",
    "            next_t = bee['track_starttime'].iloc[i+1]\n",
    "\n",
    "            init = bee['track_starty'].iloc[i]\n",
    "\n",
    "            #if time passed is greater than the threshold,\n",
    "            #classify the last detection in an event\n",
    "            if (next_t - time).total_seconds() > t:\n",
    "                second = bee['track_endy'].iloc[i]\n",
    "                matched = False\n",
    "                counter = 1\n",
    "                #iterate backwards until the distance threshold\n",
    "                #is met or until they reach the first detection in\n",
    "                #the event\n",
    "                while not matched: \n",
    "                    if abs(second-init) > t2:\n",
    "                        if second > init:\n",
    "                            new_event.append('exiting')\n",
    "                        else:\n",
    "                            new_event.append('entering')\n",
    "                        matched = True\n",
    "                    elif (time - bee['track_starttime'].iloc[i-counter]).total_seconds() < t:\n",
    "                        init = bee['track_starty'].iloc[i-counter]\n",
    "                        counter += 1\n",
    "                    else:\n",
    "                        if second > init:\n",
    "                            new_event.append('exiting')\n",
    "                        elif init > second:\n",
    "                            new_event.append('entering')\n",
    "                        else:\n",
    "                            new_event.append('unknown')\n",
    "                        matched = True\n",
    "                datetime.append(time)\n",
    "                \n",
    "                \n",
    "            \n",
    "    tagID = [id] * len(new_event)\n",
    "    df = pd.DataFrame.from_dict({'tagID': tagID, 'datetime':datetime, 'event':new_event})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb932036-2a55-4718-8d97-88180bf1a0df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kashi\\AppData\\Local\\Temp\\ipykernel_6404\\1337217809.py:11: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  new = pd.concat(bees, axis = 0).reset_index()\n"
     ]
    }
   ],
   "source": [
    "bees = []\n",
    "\n",
    "beeIDs = vdf['track_tagid'].unique()\n",
    "for bee in beeIDs:\n",
    "\n",
    "    b = vdf[vdf['track_tagid'] == bee].copy().reset_index()\n",
    "    events = beeCleanPrior(b)\n",
    "    bees.append(events)\n",
    "    \n",
    "    \n",
    "new = pd.concat(bees, axis = 0).reset_index() \n",
    "new = new[['tagID','datetime','event']]\n",
    "new.to_csv(\"bee_prior.csv\", index=False)\n",
    "new\n",
    "prior = new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c6b1f4-d4ce-4795-b4f7-1f02ca0f2408",
   "metadata": {},
   "source": [
    "## Threshold-based approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34f7aa18-a872-4d92-9e3b-3d3d05779bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "entering = [\"outside_inside\",\"ramp_inside\",\"inside_inside\"]\n",
    "exiting = [\"inside_outside\",\"ramp_outside\",\"outside_outside\"]\n",
    "\n",
    "def beeCleanPrior(bee):\n",
    "\n",
    "    id = bee['track_tagid'].iloc[0]\n",
    "\n",
    "    new_event = []\n",
    "    datetime = []\n",
    "        \n",
    "    for i in range(len(bee)-1):\n",
    "\n",
    "            time = bee['track_endtime'].iloc[i]\n",
    "            next_t = bee['track_starttime'].iloc[i+1]\n",
    "\n",
    "            #if time passed is greater than the threshold,\n",
    "            #classify the last detection in an event\n",
    "            if (next_t - time).total_seconds() > t:\n",
    "                if bee['track_shape'].iloc[i] in entering:\n",
    "                    new_event.append('entering')\n",
    "                elif bee['track_shape'].iloc[i] in exiting:\n",
    "                    new_event.append('exiting')\n",
    "                else:\n",
    "                    new_event.append('unknown')\n",
    "                datetime.append(time)\n",
    "                \n",
    "                \n",
    "            \n",
    "    tagID = [id] * len(new_event)\n",
    "    df = pd.DataFrame.from_dict({'tagID': tagID, 'datetime':datetime, 'event':new_event})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a809c42f-3e1e-482b-ac6c-79ac6df5dca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kashi\\AppData\\Local\\Temp\\ipykernel_6404\\1632906819.py:11: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  new = pd.concat(bees, axis = 0).reset_index()\n"
     ]
    }
   ],
   "source": [
    "bees = []\n",
    "\n",
    "beeIDs = vdf['track_tagid'].unique()\n",
    "for bee in beeIDs:\n",
    "\n",
    "    b = vdf[vdf['track_tagid'] == bee].copy().reset_index()\n",
    "    events = beeCleanPrior(b)\n",
    "    bees.append(events)\n",
    "    \n",
    "    \n",
    "new = pd.concat(bees, axis = 0).reset_index() \n",
    "new = new[['tagID','datetime','event']]\n",
    "new.to_csv(\"bee_threshold.csv\", index=False)\n",
    "new\n",
    "threshold = new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70434ac-f765-44f6-b5bc-5192d7e7c8d1",
   "metadata": {},
   "source": [
    "## Classify events based on summed vector angle of all detections corresponding to an event\n",
    "\n",
    "Obtained from BeeCam-AprilTag\n",
    "https://github.com/AERS-Lab/BeeCam-AprilTag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d21f6495-2d89-42ee-9c29-37eb2fcc49f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def beeCleanAngle(bee):\n",
    "\n",
    "    id = bee['track_tagid'].iloc[0]\n",
    "    new_event = []\n",
    "    datetime = []\n",
    "    vector_x = []\n",
    "    vector_y = []\n",
    "\n",
    "    \n",
    "    enter_min = 180 + angle\n",
    "    enter_max = 360 - angle\n",
    "    exit_min = angle\n",
    "    exit_max = 180 - angle\n",
    "        \n",
    "    \n",
    "    for i in range(len(bee)-1):\n",
    "\n",
    "            time = bee['track_endtime'].iloc[i]\n",
    "            next_t = bee['track_starttime'].iloc[i+1]\n",
    "\n",
    "            #obtain direction vector \n",
    "            #normalized to a magnitude of 1\n",
    "            y1 = bee['track_starty'].iloc[i]\n",
    "            y2 = bee['track_endy'].iloc[i]\n",
    "            x1 = bee['track_startx'].iloc[i]\n",
    "            x2 = bee['track_endx'].iloc[i]\n",
    "\n",
    "            dx = x2-x1\n",
    "            dy = y2-y1\n",
    "            angle_rad = np.arctan2(dy, dx)\n",
    "            unit_dx = np.cos(angle_rad)\n",
    "            unit_dy = np.sin(angle_rad)\n",
    "\n",
    "            vector_x.append(unit_dx)\n",
    "            vector_y.append(unit_dy)\n",
    "            \n",
    "            #if next detection is further than the threshold,\n",
    "            #utilize all stored angles to calculate event trajectory\n",
    "            if (next_t - time).total_seconds() > t:\n",
    "                #obtain average\n",
    "                avg_x = sum(vector_x)/len(vector_x)\n",
    "                avg_y = sum(vector_y)/len(vector_y)\n",
    "\n",
    "                if avg_x == 0 and avg_y == 0:\n",
    "                    deg = 0\n",
    "                elif avg_x == 0 and avg_y != 0:\n",
    "                    if avg_y > 0:\n",
    "                        deg = 270\n",
    "                    elif avg_y < 0:\n",
    "                        deg = 90\n",
    "                else:\n",
    "                    # determine direction angle using arctan\n",
    "                    deg = np.rad2deg(np.arctan(avg_y/avg_x))\n",
    "                    \n",
    "                    # since arctan limits are (-90,90), use coordinate directions to \n",
    "                    # correct the angle to be within standard [0,360) range\n",
    "                    if avg_x > 0 and avg_y >= 0:\n",
    "                        deg = deg\n",
    "                    elif avg_x < 0 and avg_y >= 0:\n",
    "                        deg = 180 + deg\n",
    "                    elif avg_x < 0 and avg_y < 0:\n",
    "                        deg = deg + 180\n",
    "                    elif avg_x > 0 and avg_y < 0:\n",
    "                        deg = 360 + deg\n",
    "\n",
    "                #classify events based on angle threshold\n",
    "                if deg >= exit_min and deg <= exit_max:\n",
    "                    new_event.append('exiting')\n",
    "                elif deg >= enter_min and deg <= enter_max:\n",
    "                    new_event.append('entering')\n",
    "                else:\n",
    "                    new_event.append('unknown')\n",
    "                datetime.append(time)\n",
    "                vector_x = []\n",
    "                vector_y = []\n",
    "            \n",
    "    tagID = [id] * len(new_event)\n",
    "    df = pd.DataFrame.from_dict({'tagID': tagID, 'datetime':datetime, 'event':new_event})\n",
    "    #print(bee)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a461a22f-3c9c-4dd5-a735-f7984bc4b4c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kashi\\AppData\\Local\\Temp\\ipykernel_6404\\1310600663.py:12: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  new = pd.concat(bees, axis = 0).reset_index()\n"
     ]
    }
   ],
   "source": [
    "bees = []\n",
    "\n",
    "beeIDs = vdf['track_tagid'].unique()\n",
    "for bee in beeIDs:\n",
    "\n",
    "    b = vdf[vdf['track_tagid'] == bee].copy().reset_index()\n",
    "    events = beeCleanAngle(b)\n",
    "    #print(events)\n",
    "    bees.append(events)\n",
    "    \n",
    "    \n",
    "new = pd.concat(bees, axis = 0).reset_index() \n",
    "new = new[['tagID','datetime','event']]\n",
    "new.to_csv(\"bee_angle.csv\", index=False)\n",
    "new\n",
    "summed = new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103af7d4-b896-4c94-a5f0-2660c96c1fea",
   "metadata": {},
   "source": [
    "## Classify events based on last angle corresponding to an event\n",
    "\n",
    "Modified from BeeCam-AprilTag\n",
    "https://github.com/AERS-Lab/BeeCam-AprilTag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f387bf1-7a1c-4699-b5c2-78221fdf02a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def beeCleanSingleAngle(bee):\n",
    "\n",
    "    id = bee['track_tagid'].iloc[0]\n",
    "    new_event = []\n",
    "    datetime = []\n",
    "    \n",
    "    enter_min = 180 + angle\n",
    "    enter_max = 360 - angle\n",
    "    exit_min = angle\n",
    "    exit_max = 180 - angle\n",
    "        \n",
    "    \n",
    "    for i in range(len(bee)-1):\n",
    "\n",
    "            time = bee['track_endtime'].iloc[i]\n",
    "            next_t = bee['track_starttime'].iloc[i+1]\n",
    "\n",
    "            #if time is over threshold\n",
    "            #utilize last movement angle to predict trajectory\n",
    "            if (next_t - time).total_seconds() > t:\n",
    "\n",
    "                y1 = bee['track_starty'].iloc[i]\n",
    "                y2 = bee['track_endy'].iloc[i]\n",
    "                x1 = bee['track_startx'].iloc[i]\n",
    "                x2 = bee['track_endx'].iloc[i]\n",
    "    \n",
    "                dx = x2-x1\n",
    "                dy = y2-y1\n",
    "                angle_rad = np.arctan2(dy, dx)\n",
    "                avg_x = np.cos(angle_rad)\n",
    "                avg_y = np.sin(angle_rad)\n",
    "\n",
    "                if avg_x == 0 and avg_y == 0:\n",
    "                    deg = 0\n",
    "                elif avg_x == 0 and avg_y != 0:\n",
    "                    if avg_y > 0:\n",
    "                        deg = 270\n",
    "                    elif avg_y < 0:\n",
    "                        deg = 90\n",
    "                else:\n",
    "                    # determine direction angle using arctan\n",
    "                    deg = np.rad2deg(np.arctan(avg_y/avg_x))\n",
    "                    \n",
    "                    # since arctan limits are (-90,90), use coordinate directions to \n",
    "                    # correct the angle to be within standard [0,360) range\n",
    "                    if avg_x > 0 and avg_y >= 0:\n",
    "                        deg = deg\n",
    "                    elif avg_x < 0 and avg_y >= 0:\n",
    "                        deg = 180 + deg\n",
    "                    elif avg_x < 0 and avg_y < 0:\n",
    "                        deg = deg + 180\n",
    "                    elif avg_x > 0 and avg_y < 0:\n",
    "                        deg = 360 + deg\n",
    "\n",
    "                #print(deg)\n",
    "                if deg >= exit_min and deg <= exit_max:\n",
    "                    new_event.append('exiting')\n",
    "                elif deg >= enter_min and deg <= enter_max:\n",
    "                    new_event.append('entering')\n",
    "                else:\n",
    "                    new_event.append('unknown')\n",
    "                datetime.append(time)\n",
    "            \n",
    "    tagID = [id] * len(new_event)\n",
    "    df = pd.DataFrame.from_dict({'tagID': tagID, 'datetime':datetime, 'event':new_event})\n",
    "    #print(bee)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "574307ad-482f-4bf1-8243-a4090c4b5a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kashi\\AppData\\Local\\Temp\\ipykernel_6404\\3964587374.py:12: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  new = pd.concat(bees, axis = 0).reset_index()\n"
     ]
    }
   ],
   "source": [
    "bees = []\n",
    "\n",
    "beeIDs = vdf['track_tagid'].unique()\n",
    "for bee in beeIDs:\n",
    "\n",
    "    b = vdf[vdf['track_tagid'] == bee].copy().reset_index()\n",
    "    events = beeCleanSingleAngle(b)\n",
    "    #print(events)\n",
    "    bees.append(events)\n",
    "    \n",
    "    \n",
    "new = pd.concat(bees, axis = 0).reset_index() \n",
    "new = new[['tagID','datetime','event']]\n",
    "new.to_csv(\"bee_singleangle.csv\", index=False)\n",
    "new\n",
    "single = new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c35618ee-62bb-43c9-9ba2-5297267aae7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cheatsheet = pd.read_csv(\"cheatsheet.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48efe516-eda6-4ba3-82d6-7609e6caa40e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prior': 0.8901098901098901,\n",
       " 'summedvector': 0.1043956043956044,\n",
       " 'single': 0.8296703296703297,\n",
       " 'threshold': 0.45054945054945056}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct = {'prior':0,'summedvector':0,'single':0,'threshold':0}\n",
    "for index, row in cheatsheet.iterrows():\n",
    "    if prior['event'].iloc[int(row['line'])-1] == row['event']:\n",
    "        correct['prior'] += 1\n",
    "    if summed['event'].iloc[int(row['line'])-1] == row['event']:\n",
    "        correct['summedvector'] += 1\n",
    "    if single['event'].iloc[int(row['line'])-1] == row['event']:\n",
    "        correct['single'] += 1\n",
    "    if threshold['event'].iloc[int(row['line'])-1] == row['event']:\n",
    "        correct['threshold'] += 1\n",
    "\n",
    "results = {k: v/len(cheatsheet) for k, v in correct.items()}\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57ce03d2-c619-4d20-a433-87f965795d08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8692253020611229"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prior[prior['event'] == summed['event']])/len(prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866e3ecb-14d6-4aa5-9f27-aa3e101c2f86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
